{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "#from apache_beam.runners.interactive import interactive_runner\n",
    "#import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from apache_beam.runners import DataflowRunner\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions, WorkerOptions, StandardOptions\n",
    "import google.auth\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ./environ.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings from Environment Variables.\n",
    "\n",
    "project_id = os.environ.get('project_id')\n",
    "source_topic_id = os.environ.get('source_topic_id')\n",
    "dest_topic_id = os.environ.get('dest_topic_id')\n",
    "region = os.environ.get('region')\n",
    "job_id = os.environ.get('job_id')\n",
    "network = os.environ.get('network')\n",
    "subnetwork = os.environ.get('subnetwork')\n",
    "cred = os.environ.get('cred')\n",
    "key_attrib = os.environ.get('key_attrib')\n",
    "threshold_value = os.environ.get('threshold_value')\n",
    "up_threshold_yn = os.environ.get('up_threshold_yn').lower() in ('true', '1', 't')\n",
    "window_interval = os.environ.get('window_interval')    # 30 sec. Tumbling Window Period. \n",
    "repeat_interval = os.environ.get('repeat_interval')    # 10 sec. If this value is greater than 0, Sliding Window Algorithm will be used. \n",
    "# For example, \n",
    "# window_interval = 10 & repeat_interval = 0. It means this procedure will use Tumbling Window algorithm with 10 second period. \n",
    "# window_interval = 20 & repeat_interval = 10. It means this procedure will use Sliding Window algorithm with 20 time spand and every 10 seconds make windows.\n",
    "dataflow_gcs_temp_location = os.environ.get('temp_location')\n",
    "dataflow_gcs_stage_location = os.environ.get('stage_location')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Set Pipeline options.  \n",
    "options = pipeline_options.PipelineOptions(flags={})\n",
    "\n",
    "if cred and cred != \"\" :\n",
    "  os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = cred\n",
    "  print (\"Credential Set\")\n",
    "\n",
    "options.view_as(GoogleCloudOptions).project = project_id\n",
    "options.view_as(GoogleCloudOptions).region = region\n",
    "options.view_as(GoogleCloudOptions).job_name = job_id\n",
    "options.view_as(GoogleCloudOptions).temp_location = dataflow_gcs_temp_location\n",
    "options.view_as(GoogleCloudOptions).staging_location = dataflow_gcs_stage_location\n",
    "\n",
    "options.view_as(StandardOptions).runner = 'DataflowRunner'\n",
    "# Sets the pipeline mode to streaming, so we can stream the data from PubSub.\n",
    "options.view_as(StandardOptions).streaming = True\n",
    "\n",
    "options.view_as(WorkerOptions).num_workers = 3\n",
    "options.view_as(WorkerOptions).network = network\n",
    "options.view_as(WorkerOptions).subnetwork = \"regions/{REGION}/subnetworks/{SUBNETWORK}\".format(REGION=region, SUBNETWORK=subnetwork)\n",
    "# \"https://www.googleapis.com/compute/alpha/projects/{PROJECT}/regions/{REGION}/subnetworks/{SUBNETWORK}\".format(PROJECT=project_id,\n",
    "#  REGION=region, SUBNETWORK=subnetwork)\n",
    "# options.view_as(pipeline_options.SetupOptions).sdk_location = ( '/root/apache-beam-custom/packages/beam/sdks/python/dist/apache-beam-%s0.tar.gz' % beam.version.__version__)\n",
    "\n",
    "google.auth.default()\n",
    "##_, options.view_as(GoogleCloudOptions).project = google.auth.default()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "## Set Source/Sink Topics\n",
    "source_topic = \"projects/{project}/topics/{topic}\".format(project=project_id, topic=source_topic_id)\n",
    "dest_topic = \"projects/{project}/topics/{topic}\".format(project=project_id, topic=dest_topic_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(options=options) #runner=interactive_runner.InteractiveRunner(), options=options)\n",
    "#p = beam.Pipeline(runner=interactive_runner.InteractiveRunner(), options=options)\n",
    "\n",
    "\n",
    "class JsonConverter:\n",
    "  def __init__(self, key_attrib):\n",
    "    self.key_attrib = key_attrib\n",
    "  def kvpair_from_json(self, obj):\n",
    "    return obj[self.key_attrib], obj\n",
    "  def bstring_from_objcntpair(self, obj_count):\n",
    "    return json.dumps(obj_count).encode('utf-8')\n",
    "\n",
    "class ThresholdFilter:\n",
    "  def __init__(self, threshold_value, up_yn):\n",
    "    self.threshold_value = threshold_value\n",
    "    self.up_yn = up_yn\n",
    "  def filter(self, txcount):\n",
    "    if self.up_yn:\n",
    "      return txcount[1] > self.threshold_value\n",
    "    else:\n",
    "      return txcount[1] < self.threshold_value\n",
    "\n",
    "metrics_jsonb = (p \n",
    "  | \"Read From PubSub\" >> beam.io.ReadFromPubSub(topic=source_topic).with_output_types(bytes)\n",
    ")\n",
    "transactions_per_key = ( metrics_jsonb \n",
    "  | \"Decode from bytes to python dictionary\" >> beam.Map(lambda x: json.loads(x.decode('utf-8'))) \n",
    "  | \"Make pairs with key & object\" >> beam.Map(JsonConverter(key_attrib).kvpair_from_json)\n",
    ")\n",
    "\n",
    "if repeat_interval > 0:\n",
    "  window = beam.WindowInto(beam.window.SlidingWindows(window_interval,repeat_interval), \n",
    "    trigger=beam.trigger.Repeatedly(beam.trigger.AfterWatermark()), \n",
    "    accumulation_mode=beam.trigger.AccumulationMode.DISCARDING)\n",
    "else:\n",
    "  window = beam.WindowInto(beam.window.FixedWindows(window_interval), \n",
    "    trigger=beam.trigger.Repeatedly(beam.trigger.AfterWatermark()), \n",
    "    accumulation_mode=beam.trigger.AccumulationMode.DISCARDING)\n",
    "\n",
    "transaction_count_per_key = (transactions_per_key \n",
    "  | \"Make Window\" >> window \n",
    "  | \"Count elements per windows & key\" >> beam.combiners.Count.PerKey() \n",
    "  | \"Filter keys with condition\" >> beam.Filter(ThresholdFilter(threshold_value, up_threshold_yn).filter) \n",
    "  | \"Extract only record\" >> beam.Map(JsonConverter(key_attrib).bstring_from_objcntpair)\n",
    "  | \"Writing to PubSub\" >> beam.io.WriteToPubSub(topic=dest_topic, with_attributes=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = DataflowRunner()\n",
    "runner.run_pipeline(p, options=options)\n",
    "# ib.show(transaction_count_per_key, include_window_info=True, duration=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataflow-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3ec187a4a7e337b0c285759956271088f169ee2c9faca5ea7eff1828e622e11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
